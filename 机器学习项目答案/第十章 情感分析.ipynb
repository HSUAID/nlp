{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 情感分析项目"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本项目的目标是基于用户提供的评论，通过算法自动去判断其评论是正面的还是负面的情感。比如给定一个用户的评论：\n",
    "- 评论1： “我特别喜欢这个电器，我已经用了3个月，一点问题都没有！”\n",
    "- 评论2： “我从这家淘宝店卖的东西不到一周就开始坏掉了，强烈建议不要买，真实浪费钱”\n",
    "\n",
    "对于这两个评论，第一个明显是正面的，第二个是负面的。 我们希望搭建一个AI算法能够自动帮我们识别出评论是正面还是负面。\n",
    "\n",
    "情感分析的应用场景非常丰富，也是NLP技术在不同场景中落地的典范。比如对于一个证券领域，作为股民，其实比较关注舆论的变化，这个时候如果能有一个AI算法自动给网络上的舆论做正负面判断，然后把所有相关的结论再整合，这样我们可以根据这些大众的舆论，辅助做买卖的决策。 另外，在电商领域评论无处不在，而且评论已经成为影响用户购买决策的非常重要的因素，所以如果AI系统能够自动分析其情感，则后续可以做很多有意思的应用。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "情感分析是文本处理领域经典的问题。整个系统一般会包括几个模块：\n",
    "- 数据的抓取： 通过爬虫的技术去网络抓取相关文本数据\n",
    "- 数据的清洗/预处理：在本文中一般需要去掉无用的信息，比如各种标签（HTML标签），标点符号，停用词等等\n",
    "- 把文本信息转换成向量： 这也成为特征工程，文本本身是不能作为模型的输入，只有数字（比如向量）才能成为模型的输入。所以进入模型之前，任何的信号都需要转换成模型可识别的数字信号（数字，向量，矩阵，张量...)\n",
    "- 选择合适的模型以及合适的评估方法。 对于情感分析来说，这是二分类问题（或者三分类：正面，负面，中性），所以需要采用分类算法比如逻辑回归，朴素贝叶斯，神经网络，SVM等等。另外，我们需要选择合适的评估方法，比如对于一个应用，我们是关注准确率呢，还是关注召回率呢？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本次项目中，我们已经给定了训练数据和测试数据，它们分别是 ``train.positive.txt``, ``train.negative.txt``， ``test_combined.txt``. 请注意训练数据和测试数据的格式不一样，详情请见文件内容。 整个项目你需要完成以下步骤：\n",
    "\n",
    "数据的读取以及清洗： 从给定的.txt中读取内容，并做一些数据清洗，这里需要做几个工作： \n",
    "- （1） 文本的读取，需要把字符串内容读进来。 \n",
    "- （2）去掉无用的字符比如标点符号，多余的空格，换行符等 \n",
    "- （3） 把文本转换成``TF-IDF``向量： 这部分直接可以利用sklearn提供的``TfidfVectorizer``类来做。\n",
    "- （4） 利用逻辑回归等模型来做分类，并通过交叉验证选择最合适的超参数\n",
    "\n",
    "项目中需要用到的数据：\n",
    "- ``train.positive.txt``, ``train.negative.txt``， ``test_combined.txt``： 训练和测试数据\n",
    "- ``stopwords.txt``： 停用词库\n",
    "\n",
    "\n",
    "你需要完成的部分为标记为`TODO`的部分。 \n",
    "\n",
    "另外，提交作业时候的注意点：\n",
    "> 1. 不要试图去创建另外一个.ipynb文件，所有的程序需要在`starter_code.ipynb`里面实现。很多的模块已经帮你写好，不要试图去修改已经定义好的函数以及名字。 当然，自己可以按需求来创建新的函数。但一定要按照给定的框架来写程序，不然判作业的时候会出现很多问题。 \n",
    "> 2. 上传作业的时候把整个文件解压成.zip文件（不要.rar格式），请不要上传图片文件，其他的都需要上传包括`README.md`。\n",
    "> 3. 确保程序能够正常运行，我们支持的环境是`Python 3`,  千万不要使用`Python 2`\n",
    "> 4. 上传前一定要确保完整性，批改过一次的作业我们不会再重新批改，会作为最终的分数来对待。 \n",
    "> 5. 作业可以讨论，但请自己完成。让我们一起遵守贪心学院的`honor code`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. File Reading: 文本读取 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import jieba  # 分词\n",
    "import re  # 正则\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def read_data(filename, positive=None):\n",
    "    f = open(filename, 'r', encoding='utf-8')\n",
    "    review_start = False\n",
    "    review_text = []\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        if not review_start and line.startswith(\"<review\"):\n",
    "            review_start = True\n",
    "            if \"label\" in line:\n",
    "                labels.append(int(line.split('\"')[-2]))\n",
    "            continue\n",
    "\n",
    "        if review_start and line == \"</review>\":\n",
    "            review_start = False\n",
    "            reviews.append(\" \".join(review_text))\n",
    "            review_text = []\n",
    "            continue\n",
    "\n",
    "        if review_start:\n",
    "            review_text.append(line)\n",
    "\n",
    "    if positive:\n",
    "        labels = [1] * len(reviews)\n",
    "    elif not positive is None:\n",
    "        labels = [0] * len(reviews)\n",
    "    f.close()\n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我终于找到同道中人啦～～～～从初中开始，我就已经喜欢上了michaeljackson.但同学们都用鄙夷的眼光看我，他们人为jackson的样子古怪甚至说＂丑＂．我当场气晕．但现在有同道中人了，我好开心！！！michaeljacksonisthemostsuccessfulsingerintheworld!!~~~\n"
     ]
    }
   ],
   "source": [
    "def process_file():\n",
    "    \"\"\"\n",
    "    读取训练数据和测试数据，并对它们做一些预处理\n",
    "    \"\"\"\n",
    "    train_pos_file = \"data/train.positive.txt\"\n",
    "    train_neg_file = \"data/train.negative.txt\"\n",
    "    test_comb_file = \"data/test.combined.txt\"\n",
    "    # TODO: 读取文件部分，把具体的内容写入到变量里面\n",
    "    train_comments = []\n",
    "    train_labels = []\n",
    "    test_comments = []\n",
    "    test_labels = []\n",
    "\n",
    "    train_comments, train_labels = read_data(train_pos_file, True)\n",
    "    comments, labels = read_data(train_neg_file, False)\n",
    "    train_comments = train_comments + comments\n",
    "    train_labels = train_labels + labels\n",
    "    test_comments, test_labels = read_data(test_comb_file)\n",
    "    print(test_comments[0])    \n",
    "    return train_comments,train_labels,test_comments,test_labels\n",
    "\n",
    "train_comments,train_labels,test_comments,test_labels = process_file()\n",
    "# print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.TextIOWrapper name='data/train.positive.txt' mode='r' encoding='cp936'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos_file = \"data/train.positive.txt\"\n",
    "open(train_pos_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "手感超好，而且黑色相比白色在转得时候不容易眼花，找童年的记忆啦。 1\n",
      "我终于找到同道中人啦～～～～从初中开始，我就已经喜欢上了michaeljackson.但同学们都用鄙夷的眼光看我，他们人为jackson的样子古怪甚至说＂丑＂．我当场气晕．但现在有同道中人了，我好开心！！！michaeljacksonisthemostsuccessfulsingerintheworld!!~~~ 0\n",
      "8064 8064\n",
      "2500 2500\n"
     ]
    }
   ],
   "source": [
    "print(train_comments[1],train_labels[1])\n",
    "print(test_comments[0],test_labels[0])\n",
    "\n",
    "print(len(train_comments),len(train_labels))\n",
    "print(len(test_comments),len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Explorary Analysis: 做一些简单的可视化分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8064 2500\n"
     ]
    }
   ],
   "source": [
    "# 训练数据和测试数据大小\n",
    "print (len(train_comments), len(test_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这里有一个假设想验证。我觉得，如果一个评论是负面的，则用户留言时可能会长一些，因为对于负面的评论，用户很可能会把一些细节写得很清楚。但对于正面的评论，用户可能就只写“非常好”，这样的短句。我们想验证这个假设。 为了验证这个假设，打算画两个直方图，分别对正面的评论和负面的评论。 具体的做法是：1. 把正面和负面评论分别收集，之后分别对正面和负面评论画一个直方图。 2.  直方图的X轴是评论的长度，所以从是小到大的顺序。然后Y轴是对于每一个长度，出现了多少个正面或者负面的评论。 通过两个直方图的比较，即可以看出``评论``是否是一个靠谱的特征。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4999 3065\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: 对于训练数据中的正负样本，分别画出一个histogram， histogram的x抽是每一个样本中字符串的长度，y轴是拥有这个长度的样本的百分比。\n",
    "#       并说出样本长度是否对情感有相关性 (需要先用到结巴分词)\n",
    "#       参考: https://baike.baidu.com/item/%E7%9B%B4%E6%96%B9%E5%9B%BE/1103834?fr=aladdin\n",
    "#       画饼状图参考: https://pythonspot.com/matplotlib-histogram/\n",
    "#                   https://matplotlib.org/3.1.1/ap/_as_gen/matplotlib.pyplot.hist.html\n",
    "len_pos = [len(str) for i, str in enumerate(train_comments) if train_labels[i] == 1]\n",
    "len_neg = [len(str) for i, str in enumerate(train_comments) if train_labels[i] == 0]\n",
    "print(len(len_pos), len(len_neg))\n",
    "\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6, 8))  #规定画布的大小\n",
    "plt.subplot(2, 1, 1)\n",
    "num_bins = 8\n",
    "plt.hist(len_pos, num_bins, facecolor='blue', alpha=0.5, density=True)\n",
    "plt.grid(True)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(len_neg, num_bins, facecolor='green', alpha=0.5, density=True)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// TODO: 情感跟评论长度是否有相关性？\n",
    "\n",
    "// 你的答案:不相关\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 文本预处理\n",
    "> 在此部分需要做文本预处理方面的工作。 分为几大块：\n",
    "- ``去掉特殊符号``  比如#$.... 这部分的代码已经给出，不需要自己写\n",
    "- ``把数字转换成特殊单词`` 把数字转换成 \" NUM \"， 这部分需要写。 注意：NUM前面和后面加一个空格，这样可以保证之后分词时被分掉。\n",
    "- ``分词并过滤掉停用词`` 停用词库已经提供，需要读取停用词库，并按照此停用词库做过滤。 停用词库使用给定的文件：``stopwords.txt`` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_symbols(text):\n",
    "    \"\"\"\n",
    "    对特殊符号做一些处理，此部分已写好。如果不满意也可以自行改写，不记录分数。\n",
    "    \"\"\"\n",
    "    #text = re.sub('[!！]+', \"!\", text)\n",
    "    #text = re.sub('[?？]+', \"?\", text)\n",
    "    #text = re.sub('[~~ ]+', \"~\", text)\n",
    "    text = re.sub('[!！]+', \" \", text)\n",
    "    text = re.sub('[?？]+', \" \", text)\n",
    "    text = re.sub('[~~ ]+', \" \", text)\n",
    "    text = re.sub('[～～ ]+', \" \", text)\n",
    "    text = re.sub(\"[a-zA-Z#$%&\\'()*+,-./:;：<=>@，。★、…【】《》“”‘’[\\\\]^_`{|}~]+\",\" \", text)\n",
    "    return re.sub(\"\\s+\", \" \", text)\n",
    "\n",
    "\n",
    "def load_file(file):\n",
    "    content = []\n",
    "    with open(file, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in file:\n",
    "            content += line.strip()\n",
    "    return content\n",
    "\n",
    "\n",
    "def replace_num(text):\n",
    "    return re.sub(\"\\d+\", ' NUM ', text)\n",
    "\n",
    "\n",
    "def process_text(text, stopwords):\n",
    "    text = clean_symbols(text)\n",
    "    text = replace_num(text)\n",
    "    text = \" \".join([term for term in jieba.cut(text) if term and not term in stopwords])\n",
    "    return text\n",
    "\n",
    "\n",
    "# TODO：对于train_comments, test_comments进行字符串的处理，几个考虑的点：\n",
    "#   1. 去掉特殊符号\n",
    "#   2. 把数字转换成特殊字符或者单词\n",
    "#   3. 分词并做停用词过滤\n",
    "#   4. ... （或者其他）\n",
    "#\n",
    "#   需要注意的点是，由于评论数据本身很短，如果去掉的太多，很可能字符串长度变成0\n",
    "#   预处理部分，可以自行选择合适的方.\n",
    "stopwords = load_file(\"data/stopwords.txt\")\n",
    "train_comments_cleaned = [process_text(text, stopwords) for text in train_comments]\n",
    "test_comments_cleaned = [process_text(text, stopwords) for text in test_comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 终于 找到 同道中人 啦   从 初中 开始   我 就 已经 喜欢 上 了   但 同学 们 都 用 鄙夷 的 眼光 看 我   他们 人为   的 样子 古怪 甚至 说 ＂ 丑 ＂ ． 我 当场 气晕 ． 但 现在 有 同道中人 了   我 好开心  \n"
     ]
    }
   ],
   "source": [
    "# 打印一下看看\n",
    "# print (train_comments_cleaned[0], test_comments_cleaned[0])\n",
    "# print (train_comments_cleaned[1], test_comments_cleaned[1])\n",
    "print(test_comments_cleaned[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 把文本转换成向量\n",
    "> 预处理好文本之后，我们就需要把它转换成向量形式，这里我们使用tf-idf的方法。 sklearn自带此功能，直接调用即可。输入就是若干个文本，输出就是每个文本的tf-idf向量。详细的使用说明可以在这里找到： 参考：https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html  这里需要特别注意的一点是：对于训练数据调用fit_transform, 也就是训练的过程。 但对于测试数据，不能再做训练，而是直接使用已经训练好的object做transform操作。思考一下为什么要这么做？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 17764)\t0.18868626709504846\n",
      "  (0, 16579)\t0.2830530819427771\n",
      "  (0, 15770)\t0.20983214458517935\n",
      "  (0, 15650)\t0.1376302312170629\n",
      "  (0, 14085)\t0.3181253524378206\n",
      "  (0, 13469)\t0.21898375226703318\n",
      "  (0, 10907)\t0.21544048219177275\n",
      "  (0, 9562)\t0.27884142280477353\n",
      "  (0, 9323)\t0.17548816349598256\n",
      "  (0, 8878)\t0.1507027634532857\n",
      "  (0, 7667)\t0.3181253524378206\n",
      "  (0, 6295)\t0.11051076639000804\n",
      "  (0, 5766)\t0.22829089639998063\n",
      "  (0, 5442)\t0.3181253524378206\n",
      "  (0, 4188)\t0.307838481985474\n",
      "  (0, 2312)\t0.17824011899080325\n",
      "  (0, 2114)\t0.3181253524378206\n",
      "(8064, 23328) (2500, 23328) (8064,) (2500,)\n"
     ]
    }
   ],
   "source": [
    "# TODO: 利用tf-idf从文本中提取特征,写到数组里面. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "#       参考：\n",
    "tfidf_model = TfidfVectorizer().fit(train_comments_cleaned)\n",
    "X_train =  tfidf_model.transform(train_comments_cleaned)# 训练数据的特征\n",
    "y_train =  train_labels# 训练数据的label\n",
    "X_test =   tfidf_model.transform(test_comments_cleaned)# 测试数据的特征\n",
    "y_test =   test_labels# 测试数据的label\n",
    "\n",
    "# print(X_train[0],y_train[0])\n",
    "# print(X_train[0][0][0])\n",
    "print(X_test[0])\n",
    "print (np.shape(X_train), np.shape(X_test), np.shape(y_train), np.shape(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 通过交叉验证来训练模型\n",
    "> 接下来需要建模了！ 这里我们分别使用逻辑回归，朴素贝叶斯和SVM来训练。针对于每一个方法我们使用交叉验证（gridsearchCV)， 并选出最好的参数组合，然后最后在测试数据上做验证。 这部分已经在第二次作业中讲过。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1         0.1274275   0.16237767  0.20691381  0.26366509  0.33598183\n",
      "  0.42813324  0.54555948  0.6951928   0.88586679  1.12883789  1.43844989\n",
      "  1.83298071  2.33572147  2.97635144  3.79269019  4.83293024  6.15848211\n",
      "  7.8475997  10.        ]\n",
      "{'C': 1.1288378916846888}\n",
      "[1 1 0 ... 1 0 1]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.54      0.67      1250\n",
      "           1       0.67      0.92      0.77      1250\n",
      "\n",
      "    accuracy                           0.73      2500\n",
      "   macro avg       0.77      0.73      0.72      2500\n",
      "weighted avg       0.77      0.73      0.72      2500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "# TODO： 利用逻辑回归来训练模型\n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用grid search https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       逻辑回归的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "#       对于逻辑回归，经常调整的超参数为： C\n",
    "params_c = np.logspace(-1, 1, 20)  #1.43\n",
    "print(params_c)\n",
    "param_grid = [{'C': params_c}]\n",
    "grid_model = GridSearchCV(LogisticRegression(penalty=\"l2\"),\n",
    "                          cv=3,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='f1',\n",
    "                          n_jobs=-1)\n",
    "grid_model.fit(X_train, y_train)\n",
    "print(grid_model.best_params_)\n",
    "predictions = grid_model.predict(X_test)\n",
    "print(predictions)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.31      0.47      1250\n",
      "           1       0.59      0.98      0.73      1250\n",
      "\n",
      "    accuracy                           0.65      2500\n",
      "   macro avg       0.76      0.65      0.60      2500\n",
      "weighted avg       0.76      0.65      0.60      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# TODO： 利用朴素贝叶斯来训练模型\n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用grid search https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       朴素贝叶斯的使用方法请参考：https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB\n",
    "#       对于朴素贝叶斯，一般不太需要超参数的调节。但如果想调参，也可以参考上面的链接，有几个参数是可以调节的。\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.54      0.67      1250\n",
      "           1       0.67      0.92      0.77      1250\n",
      "\n",
      "    accuracy                           0.73      2500\n",
      "   macro avg       0.77      0.73      0.72      2500\n",
      "weighted avg       0.77      0.73      0.72      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "# TODO： 利用SVM来训练模型\n",
    "#       1. 评估方式： F1-score\n",
    "#       2. 超参数（hyperparater）的选择利用grid search https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#       3. 打印出在测试数据中的最好的结果（precision, recall, f1-score, 需要分别打印出正负样本，以及综合的）\n",
    "#       请注意：做交叉验证时绝对不能用测试数据。 测试数据只能用来最后的”一次性“检验。\n",
    "#       SVM的使用方法请参考：http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#       对于SVM模型，经常调整的超参数为：C, gamma, kernel。 这里的参数C跟逻辑回归是一样的， gamma和kernel是针对于SVM的参数\n",
    "#       在这里先不要考虑他们的含义（或者通过官方文档试图理解一下）， 在课程最后的部分会讲到这些内容。\n",
    "params_c = [1,1.5,2,2.5,3,3.5,4,4.5,5]\n",
    "param_grid = [\n",
    "    {'C': params_c},\n",
    "    {'gamma':[0.125, 0.25, 0.5 ,1, 2, 4]},\n",
    "    {'kernel':['linear', 'rbf']}\n",
    "]\n",
    "grid_model = GridSearchCV(SVC(),\n",
    "                          cv=3,\n",
    "                          param_grid=param_grid,\n",
    "                          scoring='f1',\n",
    "                          n_jobs=-1)\n",
    "grid_model.fit(X_train, y_train)\n",
    "print(grid_model.best_params_)\n",
    "predictions = grid_model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 对于超参数的调整，我们经常使用gridsearch，这也是工业界最常用的方法，但它的缺点是需要大量的计算，所以近年来这方面的研究也成为了重点。 其中一个比较经典的成果为Bayesian Optimization（利用贝叶斯的思路去寻找最好的超参数）。Ryan P. Adams主导的Bayesian Optimization利用高斯过程作为后验概率（posteior distribution）来寻找最优解。 https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf 在下面的练习中，我们尝试使用Bayesian Optimization工具来去寻找最优的超参数。参考工具：https://github.com/fmfn/BayesianOptimization  感兴趣的朋友可以去研究一下。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 思考题 \n",
    "1. 对于情感分析来说，有一个问题也很重要，比如一个句子里出现了 “我不太兴奋”， “不是很满意”。 在这种情况，因为句子中出现了一些积极的词汇很可能被算法识别成正面的，但由于前面有一个“不”这种关键词，所以否定+肯定=否定，算法中这种情况也需要考虑。另外，否定+否定=肯定， 这种情况也一样。 \n",
    "2. 另外一个问题是aspect-based sentiment analysis, 这个指的是做情感分析的时候，我们既想了解情感，也想了解特定的方面。 举个例子： “这部手机的电池性能不错，但摄像不够清晰啊!”, 分析完之后可以得到的结论是： “电池：正面， 摄像：负面”， 也就是针对于一个产品的每一个性能做判定，这种问题我们叫做aspect-based sentiment analysis，也是传统情感分析的延伸。\n",
    "\n",
    ">``Q``: 对于如上两个问题，有什么解决方案？ 大概列一下能想到的处理方案。 用简介的文字来描述即可。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// 你的答案在这里.......\n",
    "1.可以单独考虑这类问题，把\"不是很，不太。。。\"这类词在分词的时候分到一块\n",
    "2.遇到aspect-based sentiment analysis这类问题，可以单独搞一个中性类别，将原来的2分类问题转为3分类问题\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=#FF0000 size=4 face=\"黑体\">对于该思考体关于多方面情感的问题，你可以多去博客先做简单了解，参考https://zhuanlan.zhihu.com/p/44580856</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 其他领域（仅供参考）\n",
    "跟情感分析类似的领域有叫affective computing, 也就是用来识别情绪(emotion recognition)。但情感和情绪又不太一样，情绪指的是高兴，低落，失落，兴奋这些人的情绪。我们知道真正的人工智能是需要读懂人类的情绪的。而且情绪识别有很多场景，比如服务机器人根据不同的情绪来跟用户交流； 无人驾驶里通过识别用户的情绪（摄像头或者声音或者传感器）来保证安全驾驶； IOT领域里设备也需要读懂我们的情绪； 微博里通过文本读懂每个人发文时的情绪。 \n",
    "\n",
    "总体来讲，情绪识别跟情感识别所用到的技术是类似的，感兴趣的小伙伴，也可以关注一下这个领域。 如果想发论文，强烈建议选择情绪方面的，不建议选择情感分析，因为问题太老了。情绪分析是近几年才开始受关注的领域。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
